{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe77b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a038193",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Data/Images\"\n",
    "caption_path = \"Data/captions.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5845ee1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'image,caption\\n'\n",
      "'1000268201_693b08cb0e.jpg,A child in a pink dress is climbing up a set of stairs in an entry way .\\n'\n",
      "'1000268201_693b08cb0e.jpg,A girl going into a wooden building .\\n'\n",
      "'1000268201_693b08cb0e.jpg,A little girl climbing into a wooden playhouse .\\n'\n",
      "'1000268201_693b08cb0e.jpg,A little girl climbing the stairs to her playhouse .\\n'\n"
     ]
    }
   ],
   "source": [
    "with open(\"Data/captions.txt\", \"r\") as file:\n",
    "    for i in range(5):\n",
    "        print(repr(file.readline()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ace5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_captions(filename):\n",
    "    captions_dict = {}\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # skip header: image,caption\n",
    "        for row in reader:\n",
    "            if len(row) != 2:\n",
    "                continue  # skip malformed lines\n",
    "            image_id, caption = row\n",
    "            image_id = image_id.strip()\n",
    "            caption = caption.strip()\n",
    "\n",
    "            if image_id not in captions_dict:\n",
    "                captions_dict[image_id] = []\n",
    "            captions_dict[image_id].append(caption)\n",
    "    return captions_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "006628bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8091 image captions.\n"
     ]
    }
   ],
   "source": [
    "caption_path = \"Data/captions.txt\"\n",
    "captions_dict = load_captions(caption_path)\n",
    "print(f\"Loaded {len(captions_dict)} image captions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec10a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_caption(caption):\n",
    "    caption = caption.lower()\n",
    "    caption = re.sub(r'[^\\w\\s]', '', caption)  # remove punctuation\n",
    "    caption = re.sub(r'\\s+', ' ', caption)     # remove extra spaces\n",
    "    caption = caption.strip()\n",
    "    return caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82f3ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_id, captions in captions_dict.items():\n",
    "    cleaned = [clean_caption(c) for c in captions]\n",
    "    captions_dict[img_id] = [f\"<start> {c} <end>\" for c in cleaned]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40bbbef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_captions = []\n",
    "for captions in captions_dict.values():\n",
    "    all_captions.extend(captions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb6e0ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2997\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter()\n",
    "for caption in all_captions:\n",
    "    word_counts.update(caption.split())\n",
    "\n",
    "# Filter out rare words (occurring less than 5 times)\n",
    "threshold = 5\n",
    "vocab = [word for word, count in word_counts.items() if count >= threshold]\n",
    "\n",
    "# Add special tokens\n",
    "vocab = ['<pad>', '<start>', '<end>', '<unk>'] + vocab\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c29aa47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
    "index_to_word = {i: word for word, i in word_to_index.items()}\n",
    "\n",
    "# Save for later use\n",
    "import numpy as np\n",
    "np.save('Data/word_to_index.npy', word_to_index)\n",
    "np.save('Data/index_to_word.npy', index_to_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38b07ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max caption length: 38\n"
     ]
    }
   ],
   "source": [
    "caption_lengths = [len(caption.split()) for caption in all_captions]\n",
    "MAX_LENGTH = max(caption_lengths)  # or use np.percentile(caption_lengths, 95)\n",
    "print(\"Max caption length:\", MAX_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bd75674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_to_seq(caption, word_to_index, max_length):\n",
    "    tokens = caption.split()\n",
    "    seq = [word_to_index.get(word, word_to_index['<unk>']) for word in tokens]\n",
    "    \n",
    "    # Pad or truncate\n",
    "    if len(seq) < max_length:\n",
    "        seq += [word_to_index['<pad>']] * (max_length - len(seq))\n",
    "    else:\n",
    "        seq = seq[:max_length]\n",
    "        \n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8ba5069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All caption sequences shape: (40455, 38)\n"
     ]
    }
   ],
   "source": [
    "all_sequences = []\n",
    "\n",
    "for captions in captions_dict.values():\n",
    "    for caption in captions:\n",
    "        seq = caption_to_seq(caption, word_to_index, MAX_LENGTH)\n",
    "        all_sequences.append(seq)\n",
    "\n",
    "all_sequences = np.array(all_sequences)\n",
    "print(\"All caption sequences shape:\", all_sequences.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25d8eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Data/captions_sequences.npy\", all_sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e1c63",
   "metadata": {},
   "source": [
    "PRE PROCESSING IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7073e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a7b6018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m96112376/96112376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load InceptionV3 and remove the final classification layer\n",
    "base_model = InceptionV3(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41401c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input(img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aad0ec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8091/8091 [30:58<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for 8091 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"Data/Images\"  # your image folder\n",
    "\n",
    "def extract_features(image_dir):\n",
    "    features = {}\n",
    "    for img_name in tqdm(os.listdir(image_dir)):\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "\n",
    "        try:\n",
    "            img_tensor = preprocess_image(img_path)\n",
    "            feature_vector = model.predict(img_tensor, verbose=0)\n",
    "            features[img_name] = feature_vector.flatten()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_name}: {e}\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "features = extract_features(image_dir)\n",
    "print(f\"Extracted features for {len(features)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e0dff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Data/image_features.npy\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99101d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
